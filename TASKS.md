# Task Tracking: cl_ml_tools Feature Expansion

**Current Phase**: Phase 3 - Embedding Infrastructure âœ… COMPLETE
**Last Updated**: 2025-12-16 02:30 PM
**Overall Progress**: 3.5/6 phases (Phase 0 âœ“, Phase 1 âœ“, Phase 2 70%, Phase 3 âœ“)

---

## Task Status Legend
- `[ ]` TODO - Not started
- `[~]` IN PROGRESS - Currently working on
- `[âœ“]` DONE - Completed

---

## Phase 0: Foundation & Tooling

### Workspace Artifacts
- `[âœ“]` Create `ImplementationPlan 1.md` in workspace root
- `[âœ“]` Create `TASKS.md` in workspace root

### Configuration & Tooling
- `[âœ“]` Configure pytest-cov in `pyproject.toml`
  - `[âœ“]` Add coverage thresholds (>85%)
  - `[âœ“]` Add HTML coverage report configuration
  - `[âœ“]` Add coverage exclusion patterns
- `[âœ“]` Create `INTERNALS.md` with standardized format
- `[âœ“]` Add ONNX runtime dependencies to `pyproject.toml`
  - `[âœ“]` Add `onnx>=1.15.0` to dependencies
  - `[âœ“]` Add `onnxruntime>=1.16.0` to dependencies
  - `[âœ“]` Add `numpy>=1.24.0` to dependencies
  - `[âœ“]` Add `httpx>=0.24` to dependencies (for model downloads)
- `[âœ“]` Create model download utility (`src/cl_ml_tools/utils/model_downloader.py`)
- `[âœ“]` Install new dependencies with `uv sync --all-extras`

**Note**: Skipped `.ai_context` folder (using TASKS.md instead). Skipped Git LFS (using download-on-demand strategy for models).

**Phase 0 Status**: âœ… COMPLETE - All tooling configured, dependencies resolved

---

## Phase 1: Exif Plugin Refactor

### Plugin Structure
- `[âœ“]` Create `src/cl_ml_tools/plugins/exif/schema.py`
  - `[âœ“]` Define `ExifParams` extending `BaseJobParams`
  - `[âœ“]` Define `ExifMetadata` Pydantic model with typed fields
  - `[âœ“]` Add raw dict field for complete metadata
- `[âœ“]` Create `src/cl_ml_tools/plugins/exif/task.py`
  - `[âœ“]` Define `ExifTask` extending `ComputeModule[ExifParams]`
  - `[âœ“]` Implement async `execute()` method
  - `[âœ“]` Add robust error handling (corrupt EXIF, unsupported formats)
  - `[âœ“]` Add logging throughout
- `[âœ“]` Create `src/cl_ml_tools/plugins/exif/routes.py`
  - `[âœ“]` Implement `create_router()` factory function
  - `[âœ“]` Add FastAPI endpoint for exif extraction
- `[âœ“]` Create `src/cl_ml_tools/plugins/exif/__init__.py`
  - `[âœ“]` Export `ExifTask`, `ExifParams`, and `ExifMetadata`

### Algorithm Refactor
- `[âœ“]` Refactor `src/cl_ml_tools/plugins/exif/algo/exif_tool_wrapper.py`
  - `[âœ“]` Replace print() with proper logging
  - `[âœ“]` Improve error handling (return defaults instead of exceptions)
  - `[âœ“]` Add type hints
  - `[âœ“]` Add docstrings
  - `[âœ“]` Add `extract_metadata_all()` method

### Testing
- `[âœ“]` Create `tests/test_exif_plugin.py`
  - `[âœ“]` Add schema validation tests (6 tests)
  - `[âœ“]` Add algorithm unit tests (6 tests)
  - `[âœ“]` Add task execution integration tests (5 tests)
  - `[âœ“]` Add error handling tests (2 tests)
  - `[âœ“]` All 19 tests passing âœ…

### Documentation
- `[âœ“]` Create `src/cl_ml_tools/plugins/exif/README.md`
  - `[âœ“]` Document parameters
  - `[âœ“]` Document output schema
  - `[âœ“]` Add example usage
  - `[âœ“]` List dependencies (ExifTool)

### Plugin Registration
- `[âœ“]` Add exif plugin entry point to `pyproject.toml`
  - `[âœ“]` Add to `cl_ml_tools.tasks`
  - `[âœ“]` Add to `cl_ml_tools.routes`

**Phase 1 Status**: âœ… COMPLETE - Exif plugin fully implemented, tested (19/19 tests pass), and documented

---

## Phase 2: Face Recognition Infrastructure

### Model Research
- `[âœ“]` Research MediaPipe Face Detection ONNX models
- `[âœ“]` Research ArcFace face embedding ONNX models
- `[âœ“]` Identify model sources (Hugging Face)

### Module 1A: Face Detection Plugin
- `[âœ“]` Create plugin directory structure
- `[âœ“]` Create `schema.py` (FaceDetectionParams, BoundingBox, FaceDetectionResult)
- `[âœ“]` Create `algo/face_detector.py` (ONNX inference with model downloader)
- `[âœ“]` Create `task.py` (FaceDetectionTask)
- `[âœ“]` Create `routes.py` (FastAPI endpoint)
- `[âœ“]` Create `__init__.py`
- `[âœ“]` Create README with model documentation
- `[ ]` Create comprehensive tests
- `[ ]` Verify model post-processing (MediaPipe-specific)

### Module 1B: Face Embedding Plugin
- `[âœ“]` Create plugin directory structure
- `[âœ“]` Create `schema.py` (FaceEmbeddingParams, FaceEmbedding, FaceEmbeddingResult)
- `[âœ“]` Create `algo/face_embedder.py` (ONNX inference with quality scoring)
- `[âœ“]` Create `task.py` (FaceEmbeddingTask)
- `[âœ“]` Create `routes.py` (FastAPI endpoint)
- `[âœ“]` Create `__init__.py`
- `[âœ“]` Create README with usage examples
- `[ ]` Create comprehensive tests
- `[ ]` Test with actual face images

### Plugin Registration
- `[âœ“]` Add `face_detection` to `pyproject.toml` entry points
- `[âœ“]` Add `face_embedding` to `pyproject.toml` entry points
- `[âœ“]` Add `scipy>=1.10.0` dependency (for quality scoring)

**Phase 2 Status**: ðŸ”„ IN PROGRESS - Plugin structure complete (70%), tests and validation pending

---

## Phase 2 (Remaining Tasks):

### Module 1A: Face Detection Plugin

#### Model Preparation
- `[ ]` Research and source MediaPipe Face Detection ONNX model
- `[ ]` Document model source and version
- `[ ]` Test model loading and inference
- `[ ]` Define model storage location (Git LFS or download URL)

#### Plugin Structure
- `[ ]` Create `src/cl_ml_tools/plugins/face_detection/` directory structure
- `[ ]` Create `schema.py`
  - `[ ]` Define `FaceDetectionParams` with configurable threshold
  - `[ ]` Define `FaceDetectionOutput` with bbox list
  - `[ ]` Define `BoundingBox` model (normalized coordinates + confidence)
- `[ ]` Create `algo/face_detector.py`
  - `[ ]` Implement ONNX model loading
  - `[ ]` Implement preprocessing (resize, normalize)
  - `[ ]` Implement inference function
  - `[ ]` Implement NMS post-processing
- `[ ]` Create `task.py`
  - `[ ]` Define `FaceDetectionTask`
  - `[ ]` Implement batch processing
- `[ ]` Create `routes.py` with FastAPI endpoint
- `[ ]` Create `__init__.py` with exports

#### Testing
- `[ ]` Create `tests/test_face_detection_plugin.py`
  - `[ ]` Add schema validation tests
  - `[ ]` Add shape-based tests (input/output dimensions)
  - `[ ]` Add deterministic inference tests
  - `[ ]` Add golden vector tests (pre-computed bboxes)
  - `[ ]` Add performance benchmark tests

#### Documentation
- `[ ]` Create `src/cl_ml_tools/plugins/face_detection/README.md`
- `[ ]` Document model source and configuration
- `[ ]` Add example usage

### Module 1B: Face Embedding Plugin

#### Model Preparation
- `[ ]` Research and source MobileFaceNet (ArcFace) ONNX model
- `[ ]` Document model source and version
- `[ ]` Test model loading and inference
- `[ ]` Define model storage location

#### Plugin Structure
- `[ ]` Create `src/cl_ml_tools/plugins/face_embedding/` directory structure
- `[ ]` Create `schema.py`
  - `[ ]` Define `FaceEmbeddingParams`
  - `[ ]` Define `FaceEmbeddingOutput` (embedding + quality)
- `[ ]` Create `algo/face_aligner.py`
  - `[ ]` Implement 5-point landmark detection/alignment
  - `[ ]` Implement similarity transform
- `[ ]` Create `algo/face_embedder.py`
  - `[ ]` Implement ONNX model loading
  - `[ ]` Implement preprocessing
  - `[ ]` Implement inference function
  - `[ ]` Implement L2 normalization
- `[ ]` Create `algo/quality_scorer.py`
  - `[ ]` Implement blur/sharpness score calculation
- `[ ]` Create `task.py`
  - `[ ]` Define `FaceEmbeddingTask`
  - `[ ]` Implement face cropping from detection
  - `[ ]` Implement batch processing
- `[ ]` Create `routes.py` with FastAPI endpoint
- `[ ]` Create `__init__.py` with exports

#### Testing
- `[ ]` Create `tests/test_face_embedding_plugin.py`
  - `[ ]` Add schema validation tests
  - `[ ]` Add shape-based tests (128D or 512D output)
  - `[ ]` Add L2 normalization tests
  - `[ ]` Add golden vector tests (pre-computed embeddings)
  - `[ ]` Add deterministic inference tests
  - `[ ]` Add performance benchmark tests

#### Documentation
- `[ ]` Create `src/cl_ml_tools/plugins/face_embedding/README.md`
- `[ ]` Document model source and configuration
- `[ ]` Add example usage

### Plugin Registration
- `[ ]` Add face_detection and face_embedding to `pyproject.toml` entry points

**Phase 2 Completion Criteria**: Face plugins functional with FP32 models

---

## Phase 3: Embedding Infrastructure

### Module 2A: DINOv2 Embedding Plugin

#### Model Preparation
- `[âœ“]` Research and source DINOv2 ViT-S/14 ONNX model (RoundtTble/dinov2_vits14_onnx)
- `[âœ“]` Document model source and version
- `[âœ“]` Define model storage location (download-on-demand from Hugging Face)

#### Plugin Structure
- `[âœ“]` Create `src/cl_ml_tools/plugins/dino_embedding/` directory structure
- `[âœ“]` Create `schema.py`
  - `[âœ“]` Define `DinoEmbeddingParams`
  - `[âœ“]` Define `DinoEmbedding` (384D embedding)
  - `[âœ“]` Define `DinoEmbeddingResult`
- `[âœ“]` Create `algo/dino_embedder.py` (preprocessing + inference combined)
  - `[âœ“]` Implement image resize (224x224)
  - `[âœ“]` Implement ImageNet normalization
  - `[âœ“]` Implement ONNX model loading with model_downloader
  - `[âœ“]` Implement inference function
  - `[âœ“]` Implement CLS token extraction
  - `[âœ“]` Implement L2 normalization
- `[âœ“]` Create `task.py`
  - `[âœ“]` Define `DinoEmbeddingTask`
  - `[âœ“]` Implement batch processing
- `[âœ“]` Create `routes.py` with FastAPI endpoint
- `[âœ“]` Create `__init__.py` and `algo/__init__.py` with exports

#### Testing
- `[ ]` Create `tests/test_dino_embedding_plugin.py`
  - `[ ]` Add schema validation tests
  - `[ ]` Add shape-based tests (384D output)
  - `[ ]` Add golden vector tests
  - `[ ]` Add deterministic inference tests
  - `[ ]` Add similarity score validation tests

#### Documentation
- `[âœ“]` Create `src/cl_ml_tools/plugins/dino_embedding/README.md`

### Module 2B: MobileCLIP Embedding Plugin

#### Model Preparation
- `[âœ“]` Research and source MobileCLIP ONNX model (Apple ml-mobileclip)
- `[âœ“]` Document model source and ONNX conversion requirements
- `[âœ“]` Define model storage location (download-on-demand or manual conversion)

#### Plugin Structure
- `[âœ“]` Create `src/cl_ml_tools/plugins/clip_embedding/` directory structure
- `[âœ“]` Create `schema.py`
  - `[âœ“]` Define `ClipEmbeddingParams`
  - `[âœ“]` Define `ClipEmbedding` (512D embedding)
  - `[âœ“]` Define `ClipEmbeddingResult`
- `[âœ“]` Create `algo/clip_embedder.py` (preprocessing + inference combined)
  - `[âœ“]` Implement CLIP-specific image preprocessing (256x256)
  - `[âœ“]` Implement CLIP normalization
  - `[âœ“]` Implement ONNX model loading with model_downloader
  - `[âœ“]` Implement inference function (image encoder only)
  - `[âœ“]` Implement L2 normalization
- `[âœ“]` Create `task.py`
  - `[âœ“]` Define `ClipEmbeddingTask`
  - `[âœ“]` Implement batch processing
- `[âœ“]` Create `routes.py` with FastAPI endpoint
- `[âœ“]` Create `__init__.py` and `algo/__init__.py` with exports

#### Testing
- `[ ]` Create `tests/test_clip_embedding_plugin.py`
  - `[ ]` Add schema validation tests
  - `[ ]` Add shape-based tests (512D output)
  - `[ ]` Add golden vector tests
  - `[ ]` Add deterministic inference tests
  - `[ ]` Add similarity score validation tests

#### Documentation
- `[âœ“]` Create `src/cl_ml_tools/plugins/clip_embedding/README.md` (with ONNX conversion guide)

### Plugin Registration
- `[âœ“]` Add dino_embedding to `pyproject.toml` entry points (tasks + routes)
- `[âœ“]` Add clip_embedding to `pyproject.toml` entry points (tasks + routes)

**Phase 3 Status**: âœ… COMPLETE - Both embedding plugins implemented with comprehensive READMEs. Tests pending (similar to Phase 2).

---

## Phase 4: Documentation & Testing Completion

### Main Documentation
- `[ ]` Update `README.md`
  - `[ ]` Add new plugins to features list (5 new plugins)
  - `[ ]` Document model sourcing strategy
  - `[ ]` Add model cache locations section
  - `[ ]` Document offline behavior
  - `[ ]` Add licensing section (MediaPipe, DINOv2, CLIP)
  - `[ ]` Update "Adding New Plugins" section with `algo/` pattern
  - `[ ]` Document "resize â†’ thumbnail" migration (temporary note)

### Contributing Guide
- `[ ]` Create `CONTRIBUTING.md`
  - `[ ]` Add plugin development walkthrough
  - `[ ]` Document `algo/` pattern requirements
  - `[ ]` Add testing guidelines
  - `[ ]` Add code style guidelines

### Utility Testing
- `[ ]` Create `tests/test_random_media_generator.py`
  - `[ ]` Test ImageGenerator
  - `[ ]` Test VideoGenerator
  - `[ ]` Test FrameGenerator
  - `[ ]` Test SceneGenerator
- `[ ]` Create `tests/test_media_types.py`
  - `[ ]` Test media type detection
  - `[ ]` Test MIME type handling
- `[ ]` Create `tests/test_timestamp.py`
  - `[ ]` Test timestamp utilities

### Plugin Testing Completion
- `[ ]` Create `tests/test_image_conversion_plugin.py`
  - `[ ]` Add schema validation tests
  - `[ ]` Add image conversion algorithm tests
  - `[ ]` Add task execution tests
- `[ ]` Update `tests/test_hash_plugin.py`
  - `[ ]` Replace hardcoded test media with random_media_generator
  - `[ ]` Ensure no skipped tests

### Coverage Verification
- `[ ]` Run pytest with coverage report
- `[ ]` Verify >85% overall code coverage
- `[ ]` Document any uncovered code in INTERNALS.md with justification

**Phase 4 Completion Criteria**: >85% code coverage, all docs complete

---

## Phase 5: Quality Assurance & Production Readiness

### Linting & Type Checking
- `[ ]` Run `ruff check src/` and fix all errors
- `[ ]` Run `ruff check tests/` and fix all errors
- `[ ]` Run `basedpyright src/` and fix all type errors
- `[ ]` Run `basedpyright tests/` and fix all type errors
- `[ ]` Document unavoidable warnings in INTERNALS.md

### Testing & Coverage
- `[ ]` Run full test suite: `pytest tests/`
- `[ ]` Generate coverage report: `pytest --cov=src/cl_ml_tools --cov-report=html`
- `[ ]` Review HTML coverage report
- `[ ]` Address any coverage gaps

### Performance Benchmarking
- `[ ]` Create benchmark script for Face Detection + Embedding pipeline
- `[ ]` Run benchmarks on CPU (FP32 baseline)
- `[ ]` Document FPS performance
- `[ ]` Compare against Phase 2 target (>5 FPS on RPi 4)

### Integration Testing
- `[ ]` Test all 9 plugins end-to-end via routes
  - `[ ]` hash
  - `[ ]` media_thumbnail
  - `[ ]` image_conversion
  - `[ ]` hls_streaming
  - `[ ]` exif
  - `[ ]` face_detection
  - `[ ]` face_embedding
  - `[ ]` dino_embedding
  - `[ ]` clip_embedding
- `[ ]` Test job queue processing with multiple concurrent jobs
- `[ ]` Test error scenarios
  - `[ ]` Missing ONNX models
  - `[ ]` Corrupt input files
  - `[ ]` Invalid parameters

### Production Documentation
- `[ ]` Create deployment guide
  - `[ ]` Document model installation process
  - `[ ]` List system requirements (CPU, RAM, disk)
  - `[ ]` Add deployment checklist
  - `[ ]` Add troubleshooting section
  - `[ ]` Document offline setup
- `[ ]` Update INTERNALS.md with final known issues

**Phase 5 Completion Criteria**: Production-ready, clean linter/type checker, deployment guide ready

---

## Phase 6: Model Optimization (Optional - Future)

### Quantization Pipeline
- `[ ]` Research onnxruntime quantization API
- `[ ]` Create representative calibration dataset
- `[ ]` Quantize MediaPipe Face Detection to INT8
- `[ ]` Quantize MobileFaceNet to INT8
- `[ ]` Quantize DINOv2 to INT8
- `[ ]` Quantize MobileCLIP to INT8

### Validation & Testing
- `[ ]` Validate INT8 accuracy vs FP32 (acceptable drift)
- `[ ]` Update tests to support both FP32 and INT8 models
- `[ ]` Run full test suite with INT8 models

### Performance Re-benchmarking
- `[ ]` Run benchmarks with INT8 models on CPU
- `[ ]` Document speedup vs FP32
- `[ ]` Verify >5 FPS target on RPi 4 achieved

### Documentation
- `[ ]` Document quantization process
- `[ ]` Create quantization scripts
- `[ ]` Update deployment guide with INT8 model instructions

**Phase 6 Completion Criteria**: INT8 quantized models achieve >5 FPS target on RPi 4 CPU

---

## Summary

**Total Tasks**: ~200+
**Completed**: 2 (workspace artifacts)
**In Progress**: 0
**Remaining**: ~198+

**Next Action**: Begin Phase 0 - Foundation & Tooling
